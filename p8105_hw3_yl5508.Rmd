---
title: "p8105_hw3_yl5508"
author: "Yifei LIU"
date: 2023/10/09
output: github_document
---

It's a proj for HW3 about VISUALIZATION AND EDA.

```{r setup, message = FALSE}
library(p8105.datasets)
library(tidyverse)
options(scipen = 999)
options(digits = 1)
```

## Problem 1

```{r load instacart}
#Variables review
data("instacart")
head(instacart, 5)
```

First, take a quick look at the dataset.  
The `instacart` dataset contains `r nrow(instacart)` obs. and `r ncol(instacart)` variables.  
For some key variables, the delineation for such is shown as below:  
- `order_id` is order identifier, `product_id` is product identifier, `user_id` is customer identifier. `product_name` is name of the product. `aisle_id` is aisle identifier. `aisle` is the name of the aisle. `department_id` is department identifier. `department` is the name of the department.   
- `reordered`: 1 if this prodcut has been ordered by this user in the past, 0 otherwise.  
- `order_number` is the order sequence number for this user (1=first, n=nth).  
- `order_dow` indicates the day of the week on which the order was placed. `order_hour_of_day` indicates the hour of the day on which the order was placed.  

```{r ins_clean and manipulate, message = FALSE}
#(a)
ins_clean =
  instacart |>
  janitor::clean_names()

#1
ais_num =
  ins_clean |>
  group_by(aisle_id, aisle) |>
  summarise(count = n()) |>
  arrange(desc(count))
head(ais_num, 5)
#the same as: 
#2
#ais_num =
  #ins_clean |>
  #group_by(aisle_id, aisle) |>
  #count(aisle, name = "count") |>
  #arrange(-count)
```

**(a)** `r ins_clean |> summarise(n_distinct(aisle_id)) |> pull() #or using n_distinct(ins_clean |> pull(aisle))` aisles are existed in data.  
We notice that `r head(ais_num, 1) |> pull(aisle)` is the aisle that most items ordered from. The amount of items for this aisle is `r max(ais_num |> pull(count))`.  

```{r ins_ais_bargraph}
#(b)
ais_10k =
  ais_num |>
  filter(count > 10000) |>
  mutate(color = ceiling(count / 10000)) |>
  mutate(color = ifelse(color <5, as.character(color), "more"))

ais_10k_vertical =
  ais_10k |>
  ggplot(aes(x = reorder(aisle, -count), y = count, fill = factor(color))) +
  #reorder ais_10k$aisle according to ais_10k$count. 
  #Actually, it is a factors reorder function, we can use parameter "FUN" to calculate the value in one factor as the reorder criteria.
  #'fill': color the inside, 'color': color the contour.
  geom_bar(stat = "identity", alpha = .75) +
  labs(
    title = "Number of Items Ordered in Each Aisle",
    x = "Aisle",
    y = "Number of Item",
  ) +
  viridis::scale_fill_viridis(discrete = TRUE, option = "viridis", labels = c("2" = "10k-20k", "3" = "20k-30k", "4" = "30k-40k", "more" = ">40k")) +
  #connected with parameter 'fill'.
  #or using parameter 'scale_fill_hue(h = c(100, 400)) +'.
  guides(fill = guide_legend("Color by Amount")) +
  theme_minimal() +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5), axis.text.x = element_text(angle = 90, hjust = 1))
ais_10k_vertical

ais_10k_horizontal =
  ais_10k |>
  ggplot(aes(x = reorder(aisle, count), y = count, fill = factor(color))) +
  geom_bar(stat = "identity", alpha = 0.75) +
  labs(
    title = "Number of Items Ordered in Each Aisle",
    x = "Aisle",
    y = "Number of Item",
  ) +
  viridis::scale_fill_viridis(discrete = TRUE, option = "viridis", labels = c("2" = "10k-20k", "3" = "20k-30k", "4" = "30k-40k", "more" = ">40k")) +
  guides(fill = guide_legend("Color by Amount")) +
  theme_minimal() +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5)) +
  coord_flip()
ais_10k_horizontal
```

```{r ggsave, message = FALSE}
ggsave("ais_10k_vertical.png", ais_10k_vertical)
ggsave("ais_10k_horizontal.png", ais_10k_horizontal)
```

**(b)** Two bar graphs are painted in this part. The data extends in different directions.  
For the generating process, we filtered the data so that they all lie in given range. Then we created factors for later coloring process. Use `ggplot` and `geom_bar` to build graph frameworks. After that, use function in `viridis` package to color the graphs.

```{r ins_most pop, message = FALSE}
#(c)
pop_num =
  ins_clean |>
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |>
  group_by(aisle, product_name) |>
  summarise(count = n()) |>
  arrange(aisle, -count) |>
  top_n(3, wt = count)
pop_num
```

**(c)** We filtered the data so that they all lie in given range. Then we group the data by variables `aisle` and `product_name`. Use `summarise` to generate the count of specific items given to the selected groups. At last, `top_n` is used to pick the 3 products with the biggest count in selected aisles.  
The 3 most popular items in `baking ingredients` are `Light Brown Sugar`, `Pure Baking Soda`, `Cane Sugar`. In `dog food care`, they are `Snack Sticks Chicken & Rice Recipe Dog Treats`, `Organix Chicken & Brown Rice Recipe`, `Small Dog Biscuits`. In `packaged vegetables fruits`, they are `Organic Baby Spinach`, `Organic Raspberries`, `Organic Blueberries`.  

```{r ins_ave h, message = FALSE}
#(d)
ave_h =
  ins_clean |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  group_by(product_name, order_dow) |>
  summarise(ave_hour = mean(order_hour_of_day, na.rm = TRUE)) |>
  pivot_wider(names_from = order_dow, values_from = ave_hour)
ave_h
```

**(d)** We filtered the data so that they all lie in given range. Then we group the data by variables `product_name` and `order_dow`. Use `summarise` to generate the average hour of day given to the selected groups. At last, `pivot_width` is used to change the table shape, so it would meet the requirement mentioned in the problem.

## Problem 2

```{r load brfss}
#Variables review
data("brfss_smart2010")
head(brfss_smart2010, 5)
```

First, we shall take a quick look at the dataset.  
The `brfss` dataset contains `r nrow(brfss_smart2010)` obs. and `r ncol(brfss_smart2010)` variables. For some key variables, the delineation for such is shown as below:  
- `year` is the time when data is recorded.  
- `Locationabbr` is abbreviation of states.  
- `Locationdesc` is abbreviation of detailed location.  
- `Class` and `Topic` are the type of questions. `Response` is how subjects respond to the `Question`.  
- Other variables are concerned with the statistic analysis result and info about the answers.  

```{r get overallhealth}
health_clean =
  brfss_smart2010 |>
  janitor::clean_names() |>
  select(state = locationabbr, location = locationdesc, everything()) |>
  filter(topic == "Overall Health") |>
  filter(response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) |>
  mutate(response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"), ordered = TRUE)) |>
  arrange(response, year, state, location)
  #the same as: arrange(factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"), ordered = TRUE), state, specific_location, year)
head(health_clean, 5)
```

```{r health_manipulate1, message = FALSE}
hea_02 =
  health_clean |>
  filter(year == "2002") |>
  group_by(state) |>
  summarise(count = n_distinct(location)) |>
  filter(count >= 7)
hea_02 |> pull(state)
```

```{r health_manipulate2, message = FALSE}
hea_10 =
  health_clean |>
  filter(year == "2010") |>
  group_by(state) |>
  summarise(count = n_distinct(location)) |>
  filter(count >= 7)
hea_10 |> pull(state)
```

In **2002**, states which were observed at 7 or more location are shown as followed: `r hea_02 |> pull(state)`.  
In **2010**, states which were observed at 7 or more location are shown as followed: `r hea_10 |> pull(state)`.

```{r health_manipulate3, message = FALSE}
exc_hea_data =
  health_clean |>
  filter(response == "Excellent") |>
  group_by(year, state) |>
  summarise(ave_dv = mean(data_value, na.rm = TRUE))

exc_hea_data |>
  ggplot(aes(x = year, y = ave_dv, group = state, color = state)) +
  geom_line() +
  labs(
    title = "Average of Data_Value for Each State across Years",
    x = "Year",
    y = "Average_Datavalue",
  ) +
  theme_minimal() +
  theme(legend.position = "right") +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5))
```

We take `health_clean` dataset as original data, and group the data up by variables `year` and `state`. Then, use `summarise()` to get the average of `data_vale` across locations within a state. At last, a spaghetti plot is drawn from the dataset manipulated using methods as mentioned above. We can hardly interpret a trend from the plot, but only fluctuated.  

```{r health_manipulate4, message = FALSE, warning = FALSE}
health_clean |>
  filter(year == "2006" | year == "2010") |>
  filter(state == "NY") |>
  ggplot(aes(x = response, y = data_value, fill = response)) +
  geom_boxplot(alpha = 0.5) +
  labs(
    title = "Distribution of Data_Value for Responses in NY",
    x = "Response",
    y = "Data_value"
  ) +
  guides(fill = guide_legend("Response")) +
  theme_minimal() +
  facet_grid(~ year) +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5))
```

```{r health_manipulate#4, eval = FALSE, message = FALSE}
#basically the same as:
res_hea_06 =
  health_clean |>
  filter(year == "2006" & state == "NY") |>
  ggplot(aes(x = response, y = data_value)) +
  geom_boxplot() +
  theme(legend.position = "none")

res_hea_10 =
  health_clean |>
  filter(year == "2010" & state == "NY") |>
  ggplot(aes(x = response, y = data_value)) +
  geom_boxplot() +
  theme(legend.position = "none")

library(patchwork)
res_hea_06 + res_hea_10
```

Picture a plot with two panels using data filtered by variables `year` and `state` from dataset `health_clean`. We pick boxplot to show the distribution of `data_value`.  
The distribution of different responses within one year is similar for 2006 and 2010. The basic order for different responses from high data value to low one would be `Very good`, `Good`, `Excellent`, `Fair`, `Poor`. Averge data value of `Very good` is the highest and that of `Poor` is the lowest. 

## Problem 3

```{r acc and cov cleaning}
acc_clean =
  read_csv("./dataset/nhanes_accel.csv") |>
  janitor::clean_names()

cov_clean =
  read_csv("./dataset/nhanes_covar.csv", skip = 4) |>
  janitor::clean_names() |>
  drop_na()

cov_acc =
  inner_join(cov_clean, acc_clean, by = "seqn") |>
  filter(age >= 21) |>
  mutate(sex = case_match(
    sex, 
    1 ~ "male", 
    2 ~ "female"
  ), education = case_match(
    education, 
    1 ~ "less than high school", 
    2 ~ "high school equivalent", 
    3 ~ "more than high school"
  )) |>
  mutate(sex = factor(sex, levels = c("male", "female")), education = factor(education, levels = c("less than high school", "high school equivalent", "more than high school", ordered = TRUE)))
head(cov_acc, 5)
```

After dropping NA from demographic dataset , we join the data together, then exclude those less than 21 years of age, create factors for variables `sex` and `education` (not numeric) and set order for `education`.   
In summary, we get a merged dataset with `r nrow(cov_acc)` obs. and `r ncol(cov_acc)` variables.  

```{r edu_sex_cov_1, message = FALSE}
edu_cov =
  cov_acc |>
  group_by(education, sex) |>
  summarise(count = n()) |>
  pivot_wider(names_from = sex, values_from = count)
edu_cov
```

First, we select 2 key elements from the dataset `cov_acc` using function `group_by()` and extract the counting number from the processed data. After that, we create a `r nrow(edu_cov)`X`r ncol(edu_cov)` table using function `pivot_wider()` to compress the original table.  
We observe that men and women with education level `more than high school` occupy the greatest proportion in the participants population, the counting number of which can be added up to half of the total number. There's no huge gap between sexes at the education level `less than high school` and `more than high school`. But for `high school equivalent`, more men are observed than women.  

```{r edu_sex_cov_2, message = FALSE}
age_dis =
  cov_acc |>
  ggplot(aes(x = sex, y = age, fill = sex)) +
  geom_boxplot(alpha = 0.5) +
  guides(fill = guide_legend("Sex")) +
  labs(
    title = "Age against Sex and Education",
    x = "Education Level",
    y = "Age"
  ) +
  theme_minimal() +
  facet_grid(~ education) +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5))
age_dis
```

Using boxplot, we show the visulization result of age distribution for men and women. Parameter `facet_grid(~ education)` is used for dividing the plot for different education category.  
From the plot, we can see there is no significant age difference between men and women in education levels of `less than high school` and `more than high school`. However, age difference between two sexes is observed in education level `high school equivalent` and the distribution of men's age is generally smaller than that of women's.  

```{r total_activity_plot, message = FALSE}
total_acc =
  cov_acc %>%
  mutate(total_act = rowSums(select(., min1:min1440))) |>
  #'rowSums()': function used for cross-line computing. It needs a dataframe rather than names of selected variables.
  #'. (placeholder)' need to be used with pipe '%>%'.
  select(seqn, age, total_act, sex, education)

total_point =
  total_acc |>
  ggplot(aes(x = age, y = total_act, color = sex)) +
  geom_point(alpha = 0.7) +
  geom_smooth(se = FALSE) +
  labs(
    title = "Total Activity against Age, by Sex and Education",
    x = "Age",
    y = "Total Activity"
  ) +
  viridis::scale_color_viridis(discrete = TRUE, option = "viridis") +
  theme_minimal() +
  facet_grid(~ education) +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5))
total_point
```

The variable `total_act` indicates the total activity over the day, which is calculated using function `rowSums()` and data columns from `min1` to `min1440`. Then we can make the point plot and set a trend curve in it.  
From the plot, general trend in all education levels is decreasing, which indicates that typically people's activity get milder while their age increases. Worth noticing, there's one peak in this decreasing trend, which lies in interval about 50-60 for `less than high school`, 30-40 for `high school equivalent`, and 40-60 for `more than high school`. People's total activity level rises for about 5-10 years and then decreases. For education level `less than high school`, total activity level of men is higher than that of women, and the reverse is true for education level `high school equivalent` and `more than high school`. The total activity level of those in education level `less than high school` is slightly higher than that of people in other two education levels. But the total activity levels tend to be the same at older age.  

```{r 24h_accelerometerdata_plot, message = FALSE, fig.width = 12, fig.height = 6}
acc_24h =
  cov_acc |>
  pivot_longer(min1:min1440, names_to = "time_split", values_to = "MIMS") |>
  mutate(time_split = as.numeric(gsub("min", "", time_split))) |>
  select(seqn, time_split, MIMS, sex, education)

acc24h_point =
  acc_24h |>
  ggplot(aes(x = time_split, y = MIMS, color = sex)) +
  geom_point(alpha = 0.3) +
  geom_smooth(se = FALSE) +
  labs(
    title = "24h MIMS against Time Split, by Sex and Education",
    x = "Time_Split",
    y = "MIMS"
  ) +
  viridis::scale_color_viridis(discrete = TRUE, option = "viridis") +
  theme_minimal() +
  facet_grid(~ education) +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5))
acc24h_point
```

Reorganize the dataset by using function `pivot_longer()`. Set variable `time_split`(specific minute point from 24 hours) as X-axis variable, `MIMS`(activity index at specific time point) as y-axis variable. Then show different sexes in  different colors and divide the plot into 3 parts connected with different education levels.  
The trend curves(smooth lines) are basically the same for men and women. The trend of curves indicates that for period during daytime, the activity level stays in high value, and for period during nighttime, it decays to a lower level. For different education level, trend curves show a similar pattern, means that there is no significant connection between activity level and education level. But we can also notice that there're more points with extreme value in `more than high school` during noon and nightfall compared with other education levels.  

