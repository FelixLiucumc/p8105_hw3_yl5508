---
title: "p8105_hw3_yl5508"
author: "Yifei LIU"
date: 2023/10/09
output: github_document
---

It's a proj for HW3 about VISUALIZATION AND EDA.

```{r setup, echo = FALSE, message = FALSE}
library(p8105.datasets)
library(tidyverse)
options(scipen = 999)
options(digits = 1)
```

## Problem 1

```{r load instacart}
#Variables review
data("instacart")
head(instacart, 5)
```

First, we shall take a quick look at the dataset.  
The `instacart` dataset contains `r nrow(instacart)` obs. and `r ncol(instacart)` variables.
For some key variables, the delineation for such is shown as below:  
- `order_id` is order identifier, `product_id` is product identifier, `user_id` is customer identifier. `product_name` is name of the product. `aisle_id` is aisle identifier. `aisle` is the name of the aisle. `department_id` is department identifier. `department` is the name of the department.   
- `reordered`: 1 if this prodcut has been ordered by this user in the past, 0 otherwise.  
- `order_number` is the order sequence number for this user (1=first, n=nth).  
- `order_dow` indicates the day of the week on which the order was placed. `order_hour_of_day` indicates the hour of the day on which the order was placed.  

```{r ins_clean and manipulate, message = FALSE}
#(a)
ins_clean =
  instacart |>
  janitor::clean_names()

#1
ais_num =
  ins_clean |>
  group_by(aisle_id, aisle) |>
  summarise(count = n()) |>
  arrange(desc(count))
head(ais_num, 5)
#the same as: 
#2
#ais_num =
  #ins_clean |>
  #group_by(aisle_id, aisle) |>
  #count(aisle, name = "count") |>
  #arrange(-count)
```

**(a)** `r ins_clean |> summarise(n_distinct(aisle_id)) |> pull()` (or using `r n_distinct(ins_clean |> pull(aisle))`) aisles are existed in data.  
`r head(ais_num, 1) |> pull(aisle)` is aisle that most items ordered from. The amount of items for this aisle is `r max(ais_num |> pull(count))`.  

```{r ins_ais_bargraph}
#(b)
ais_10k =
  ais_num |>
  filter(count > 10000) |>
  mutate(color = ceiling(count / 10000)) |>
  mutate(color = ifelse(color <5, as.character(color), "more"))

ais_10k_vertical =
  ais_10k |>
  ggplot(aes(x = reorder(aisle, -count), y = count, fill = factor(color), color = factor(color))) +
  #reorder ais_10k$aisle according to ais_10k$count. 
  #Actually, it is a factors reorder function, we can use parameter "FUN" to calculate the value in one factor as the reorder criteria.
  #'fill': color the inside, 'color': color the contour.
  geom_bar(stat = "identity", alpha = .75) +
  labs(
    title = "Number of Items Ordered in Each Aisle",
    x = "Aisle",
    y = "Number of Item",
  ) +
  viridis::scale_fill_viridis(discrete = TRUE, option = "viridis") +
  #connected with parameter 'fill'.
  viridis::scale_color_viridis(discrete = TRUE, option = "viridis") +
  #connected with parameter 'color'.
  #or using parameter 'scale_fill_hue(h = c(100, 400)) +'.
  theme_minimal() +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5), axis.text.x = element_text(angle = 90, hjust = 1), legend.position = "none")
ais_10k_vertical

ais_10k_horizontal =
  ais_10k |>
  ggplot(aes(x = reorder(aisle, count), y = count, fill = factor(color), color = factor(color))) +
  geom_bar(stat = "identity", alpha = 0.75) +
  labs(
    title = "Number of Items Ordered in Each Aisle",
    x = "Aisle",
    y = "Number of Item",
  ) +
  viridis::scale_fill_viridis(discrete = TRUE, option = "viridis") +
  viridis::scale_color_viridis(discrete = TRUE, option = "viridis") +
  theme_minimal() +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5), legend.position = "none") +
  coord_flip()
ais_10k_horizontal
```

```{r ggsave, message = FALSE}
ggsave("ais_10k_vertical.png", ais_10k_vertical)
ggsave("ais_10k_horizontal.png", ais_10k_horizontal)
```

**(b)** Two bar graphs are painted in this part. The data extends in different directions.  
For the generating process, we filtered the data so that they all lie in given range. Then we created factors for later coloring process. Use `ggplot` and `geom_bar` to build graph frameworks. After that, use function in `viridis` package to color the graphs.

```{r ins_most pop, message = FALSE}
#(c)
pop_num =
  ins_clean |>
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |>
  group_by(aisle, product_name) |>
  summarise(count = n()) |>
  arrange(aisle, -count) |>
  top_n(3, wt = count)
pop_num
```

**(c)** We filtered the data so that they all lie in given range. Then we group the data by variables `aisle` and `product_name`. Use `summarise` to generate the count of specific items given to the selected groups. At last, `top_n` is used to pick the 3 products with the biggest count in selected aisles.

```{r ins_ave h, message = FALSE}
#(d)
ave_h =
  ins_clean |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  group_by(product_name, order_dow) |>
  summarise(ave_hour = mean(order_hour_of_day, na.rm = TRUE)) |>
  pivot_wider(names_from = order_dow, values_from = ave_hour)
ave_h
```

**(d)** We filtered the data so that they all lie in given range. Then we group the data by variables `product_name` and `order_dow`. Use `summarise` to generate the average hour of day given to the selected groups. At last, `pivot_width` is used to change the table shape, so it would meet the requirement mentioned in the problem.

## Problem 2

```{r load brfss}
#Variables review
data("brfss_smart2010")
head(brfss_smart2010, 5)
```

First, we shall take a quick look at the dataset.  
The `brfss` dataset contains `r nrow(brfss_smart2010)` obs. and `r ncol(brfss_smart2010)` variables. For some key variables, the delineation for such is shown as below:  
- `year` is the time when data is recorded.  
- `Locationabbr` is abbreviation of states.  
- `Locationdesc` is abbreviation of detailed location.  
- `Class` and `Topic` are the type of questions. `Response` is how subjects respond to the `Question`.  
- Other variables are concerned with the statistic analysis result and info about the answers.  

```{r get overallhealth}
health_clean =
  brfss_smart2010 |>
  janitor::clean_names() |>
  select(state = locationabbr, location = locationdesc, everything()) |>
  filter(topic == "Overall Health") |>
  filter(response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) |>
  mutate(response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"), ordered = TRUE)) |>
  arrange(response, year, state, location)
  #the same as: arrange(factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"), ordered = TRUE), state, specific_location, year)
head(health_clean, 5)
```

```{r health_manipulate1, message = FALSE}
hea_02 =
  health_clean |>
  filter(year == "2002") |>
  group_by(state) |>
  summarise(count = n_distinct(location)) |>
  filter(count >= 7)
hea_02 |> pull(state)
```

```{r health_manipulate2, message = FALSE}
hea_10 =
  health_clean |>
  filter(year == "2010") |>
  group_by(state) |>
  summarise(count = n_distinct(location)) |>
  filter(count >= 7)
hea_10 |> pull(state)
```

In **2002**, states which were observed at 7 or more location are shown as followed: `r hea_02 |> pull(state)`.  
In **2010**, states which were observed at 7 or more location are shown as followed: `r hea_10 |> pull(state)`.

```{r health_manipulate3, message = FALSE}
exc_hea_data =
  health_clean |>
  filter(response == "Excellent") |>
  group_by(year, state) |>
  summarise(ave_dv = mean(data_value, na.rm = TRUE))

exc_hea_data |>
  ggplot(aes(x = year, y = ave_dv, group = state, color = state)) +
  geom_line() +
  labs(
    title = "Average of Data_Value for Each State across Years",
    x = "Year",
    y = "Average_Datavalue",
  ) +
  theme_minimal() +
  theme(legend.position = "right") +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5))
```

We take `health_clean` dataset as original data, and group the data up by variables `year` and `state`. Then, use `summarise()` to get the average of `data_vale` across locations within a state. At last, a spaghetti plot is drawn from the dataset manipulated using methods as mentioned above.

```{r health_manipulate4, message = FALSE, warning = FALSE}
health_clean |>
  filter(year == "2006" | year == "2010") |>
  filter(state == "NY") |>
  ggplot(aes(x = response, y = data_value, fill = response)) +
  geom_boxplot(alpha = 0.5) +
  labs(
    title = "Distribution of Data_Value for Responses in NY",
    x = "Response",
    y = "Data_value"
  ) +
  guides(fill = guide_legend("Response")) +
  theme_minimal() +
  facet_grid(~ year) +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5))
```

```{r health_manipulate#4, eval = FALSE, message = FALSE}
#basically the same as:
res_hea_06 =
  health_clean |>
  filter(year == "2006" & state == "NY") |>
  ggplot(aes(x = response, y = data_value)) +
  geom_boxplot() +
  theme(legend.position = "none")

res_hea_10 =
  health_clean |>
  filter(year == "2010" & state == "NY") |>
  ggplot(aes(x = response, y = data_value)) +
  geom_boxplot() +
  theme(legend.position = "none")

library(patchwork)
res_hea_06 + res_hea_10
```

Picture a plot with two panels using data filtered by variables `year` and `state` from dataset `health_clean`. We pick boxplot to show the distribution of `data_value`.

## Problem 3

```{r acc and cov cleaning}
acc_clean =
  read_csv("./dataset/nhanes_accel.csv") |>
  janitor::clean_names()

cov_clean =
  read_csv("./dataset/nhanes_covar.csv", skip = 4) |>
  janitor::clean_names() |>
  drop_na()

cov_acc =
  inner_join(cov_clean, acc_clean, by = "seqn") |>
  filter(age >= 21) |>
  mutate(sex = case_match(
    sex, 
    1 ~ "male", 
    2 ~ "female"
  ), education = case_match(
    education, 
    1 ~ "less than high school", 
    2 ~ "high school equivalent", 
    3 ~ "more than high school"
  )) |>
  mutate(sex = factor(sex, levels = c("male", "female")), education = factor(education, levels = c("less than high school", "high school equivalent", "more than high school", ordered = TRUE)))
head(cov_acc, 5)
```

```{r edu_sex_cov, message = FALSE}
edu_cov =
  cov_acc |>
  group_by(education, sex) |>
  summarise(count = n()) |>
  pivot_wider(names_from = sex, values_from = count)
edu_cov

age_dis =
  cov_acc |>
  ggplot(aes(x = sex, y = age, fill = sex)) +
  geom_boxplot(alpha = 0.5) +
  guides(fill = guide_legend("sex")) +
  theme_minimal() +
  facet_grid(~ education)
age_dis
```

```{r total_activity_plot, message = FALSE}
total_acc =
  cov_acc %>%
  mutate(total_act = rowSums(select(., min1:min1440))) |>
  #'rowSums()': function used for cross-line computing. It needs a dataframe rather than names of selected variables.
  #'. (placeholder)' need to be used with pipe '%>%'.
  select(seqn, age, total_act, sex, education)

total_point =
  total_acc |>
  ggplot(aes(x = age, y = total_act, color = sex)) +
  geom_point(alpha = 0.7) +
  geom_smooth(se = FALSE) +
  labs(
    title = "Total Activity against Age, by Sex and Education",
    x = "Age",
    y = "Total Activity"
  ) +
  viridis::scale_color_viridis(discrete = TRUE, option = "viridis") +
  theme_minimal() +
  facet_grid(~ education) +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5))
total_point
```

```{r 24h_accelerometerdata_plot, message = FALSE, fig.width = 12, fig.height = 6}
acc_24h =
  cov_acc |>
  pivot_longer(min1:min1440, names_to = "time_split", values_to = "MIMS") |>
  mutate(time_split = as.numeric(gsub("min", "", time_split))) |>
  select(seqn, time_split, MIMS, sex, education)

acc24h_point =
  acc_24h |>
  ggplot(aes(x = time_split, y = MIMS, color = sex)) +
  geom_point(alpha = 0.3) +
  geom_smooth(se = FALSE) +
  labs(
    title = "24h MIMS against Time Split, by Sex and Education",
    x = "Time_Split",
    y = "MIMS"
  ) +
  viridis::scale_color_viridis(discrete = TRUE, option = "viridis") +
  theme_minimal() +
  facet_grid(~ education) +
  theme(plot.title = element_text(size = 15, face = "bold", hjust = 0.5))
acc24h_point
```



